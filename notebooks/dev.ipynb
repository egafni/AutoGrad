{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a742ff07-5fac-464f-abf3-47f0a18ed2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from nn.value import Value\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd82af70-c8cd-45c0-81b9-abb23a8cafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.value import Value, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89bd07c7-5bb8-424f-8684-536b5c87a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(5.,requires_grad=True)\n",
    "x2 = torch.tensor(3.,requires_grad=True)\n",
    "x3 = torch.exp(x1+x2) \n",
    "x3.backward()\n",
    "x1.grad, x2.grad\n",
    "z = x1.grad.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "922ae607-4b2f-499c-bcc9-a5aa86e9887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980.9579870417283, 2980.9579870417283)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = Value(5.)\n",
    "x2 = Value(3.)\n",
    "x3 = exp(x1+x2) \n",
    "x3.backward()\n",
    "x1.grad, x2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67e2514a-223b-40e0-be32-bfaa5c7bc243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2980.9580078125"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e104c9d-938b-4166-8e99-cefed29e469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(148.4132)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad1600d-c1c1-4449-9b0d-0519570faa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(148.4131591025766, grad=0.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = Value(5.)\n",
    "b1 = Value(6.)\n",
    "\n",
    "\n",
    "exp(Value(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d1fbbc-5545-4147-a4b5-c3db95a8bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "INFERENCE = False\n",
    "\n",
    "@contextmanager\n",
    "def inference_mode():\n",
    "    global INFERENCE\n",
    "    INFERENCE = true\n",
    "    yield INFERENCE\n",
    "    INFERENCE = false\n",
    "\n",
    "\n",
    "class Module:\n",
    "    def parameters(self,):\n",
    "        return self._parameters\n",
    "\n",
    "class BatchNorm:\n",
    "    def __init__(self,):\n",
    "        self.running_mean = None\n",
    "        self.running_std = None\n",
    "        self._parameters = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mean = x.mean(0, keepdims=True)\n",
    "        std = x.std(0, keepdims=True)\n",
    "\n",
    "        if INFERENCE or self.running_mean is None:\n",
    "            mean = self.running_mean\n",
    "            std = self.running_std\n",
    "        else:                        \n",
    "            self.running_mean  = self.running_mean * .999 + mean * .01\n",
    "            self.running_std  = self.running_std * .999 + std * .01\n",
    "        \n",
    "        x = x - mean / std\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class Linear(Module):\n",
    "    n_in: int\n",
    "    n_out: int\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.w = [Value(random.random(), name='w') for i in range(self.n_out)]\n",
    "        self.b = Value(random.random(), name='b')\n",
    "\n",
    "        self._parameters = self.w + [self.b]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        assert len(x) == self.n_in\n",
    "        return [sum((x[i]*self.w[j] for i in range(self.n_in)), start=self.b) for j in range(self.n_out)]\n",
    "\n",
    "@dataclass\n",
    "class Relu(Module):\n",
    "    def __init__(self):\n",
    "        self._parameters = []\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [max(0, x_.data) * x_ for x_ in x]\n",
    "\n",
    "@dataclass\n",
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        self._parameters = []\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [(exp(2*x_)-1 ) / (exp(2*x_)+1) for x_ in x]\n",
    "\n",
    "@dataclass\n",
    "class MLP(Module):\n",
    "    n_in: int\n",
    "    n_out: int\n",
    "    n_layers: int\n",
    "    n_hidden: int\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        assert self.n_layers >= 1\n",
    "        layers = [Linear(self.n_in, self.n_hidden), Tanh()]\n",
    "        \n",
    "        for i in range(self.n_layers-2):\n",
    "            layers += [Linear(self.n_hidden, self.n_hidden), Tanh()]\n",
    "            \n",
    "        layers += [Linear(self.n_hidden, self.n_out)]\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters() ]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = [layer(x_) for x_ in x]\n",
    "        return x\n",
    "\n",
    "X = inputs = [[Value(5., name='x1'), Value(6., name='x2')],\n",
    "              [Value(3., name='x1'), Value(5., name='x2')]]\n",
    "y = 2\n",
    "\n",
    "mlp = MLP(2, 1, n_layers=1, n_hidden=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23483ce-eddf-4d89-835b-1946a76666fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(w=-140811395.6500865, grad=0.0), Value(w=-54089237872.0708, grad=0.0), Value(w=-189.08374681259593, grad=0.0), Value(b=-4443179871.905231, grad=0.0), Value(w=-8168478052095251.0, grad=-541593871.5921905), Value(b=20590960663592.914, grad=180531290.53073016)]\n"
     ]
    }
   ],
   "source": [
    "lr = .001\n",
    "\n",
    "#forward\n",
    "y_hat = mlp(X)\n",
    "loss = sum((y - y_hat_[0])**2 for y_hat_ in y_hat)\n",
    "\n",
    "print(mlp.parameters())\n",
    "\n",
    "#backward\n",
    "for p in mlp.parameters():\n",
    "    p.grad = 0\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "for p in mlp.parameters():\n",
    "    p.data -= p.grad * p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad3bed7-a0cb-4af7-bc2c-034427e4aa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(4073943357586362.5, grad=1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7a2790-35aa-4317-8f0d-e01efaa013cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(w=-392.03045006390767, grad=0.0),\n",
       " Value(w=-296.0164755065418, grad=0.0),\n",
       " Value(w=-145.44493717290726, grad=0.0),\n",
       " Value(b=-91.33222568579471, grad=0.0),\n",
       " Value(w=-926.7610552891709, grad=0.0),\n",
       " Value(b=-302363111.0525898, grad=-34780.68310128581)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d93b0d-ac0c-43e9-adce-7ddd0da1d466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(622.5901125806454, grad=1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d1d68-2832-472d-9808-62c45800193c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
